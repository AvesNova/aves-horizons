# Unified Training Configuration
# Supports BC pretraining, RL training, and evaluation

# Environment Configuration
environment:
  world_size: [1200, 800]
  max_ships: 8
  agent_dt: 0.04
  physics_dt: 0.02

# Data Collection Configuration
data_collection:
  # BC Data Collection
  bc_data:
    episodes_per_mode:
      "1v1": 2500
      "2v2": 2500  
      "3v3": 2500
      "4v4": 2500
    game_modes: ["1v1", "2v2", "3v3", "4v4"]
    output_dir: "data/bc_pretraining"
    gamma: 0.99
    compress: true
  
  # Self-play Data Collection
  selfplay_data:
    total_episodes: 1000
    game_mode: "nvn"
    output_dir: "data/selfplay"
    model_paths: []  # List of model paths for self-play
    gamma: 0.99

# Model Configuration
model:
  transformer:
    token_dim: 10
    embed_dim: 64
    num_heads: 4
    num_layers: 3
    max_ships: 8
    num_actions: 6
    dropout: 0.1
    use_layer_norm: true
  
  # BC Training
  bc:
    learning_rate: 0.001
    batch_size: 128
    epochs: 50
    validation_split: 0.2
    early_stopping_patience: 10
    policy_weight: 1.0
    value_weight: 0.5
  
  # PPO Configuration
  ppo:
    learning_rate: 0.0003
    n_steps: 4096
    batch_size: 128
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5

# Training Configuration
training:
  # RL Training
  rl:
    total_timesteps: 2000000
    learning_team_id: 0
    
    # Opponent Configuration
    opponent:
      type: "mixed"  # scripted, self_play, mixed
      scripted_mix_ratio: 0.3
      selfplay_memory_size: 50
      opponent_update_freq: 10000
      
      scripted_config:
        max_shooting_range: 500.0
        angle_threshold: 5.0
        bullet_speed: 500.0
        target_radius: 10.0
        radius_multiplier: 1.5
    
    # Self-play parameters
    selfplay_update_freq: 20000
    min_steps_before_selfplay: 50000
    
    # Evaluation
    eval_freq: 25000
    eval_episodes: 20
    
    # Checkpointing
    checkpoint_freq: 100000

# Evaluation Configuration
evaluation:
  episodes: 100
  game_mode: "2v2"
  model_type: "transformer"  # transformer, ppo, bc
  
  # Multiple model comparison
  compare_models:
    enabled: false
    model_paths: []
    output_dir: "results/evaluation"

# Scripted Agent Configuration (shared across all uses)
scripted_agent:
  max_shooting_range: 500.0
  angle_threshold: 5.0
  bullet_speed: 500.0
  target_radius: 10.0
  radius_multiplier: 1.5

# Logging Configuration
logging:
  wandb:
    enabled: false
    project: "space-combat-unified"
    tags: ["unified", "transformer"]
  
  tensorboard:
    enabled: true
    log_dir: "logs"
  
  console:
    level: "INFO"
    progress_bars: true

# Paths Configuration
paths:
  models: "checkpoints"
  data: "data"
  logs: "logs"
  results: "results"
