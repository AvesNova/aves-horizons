# 1v1 training configuration
environment:
  world_size: [1200, 800]
  max_ships: 2
  agent_dt: 0.04
  physics_dt: 0.02
  memory_size: 1

training:
  game_mode: "1v1"
  learning_team_id: 0
  team_assignments:
    0: [0]  # Team 0 controls ship 0
    1: [1]  # Team 1 controls ship 1
  
  # Opponent configuration
  opponent_type: "mixed"
  scripted_mix_ratio: 0.3  # Higher scripted ratio for 1v1
  
  # Self-play parameters
  self_play_memory_size: 30
  opponent_update_freq: 5000
  self_play_update_freq: 15000
  min_steps_before_selfplay: 30000
  
  # Training parameters (shorter for 1v1)
  total_timesteps: 1000000
  
  # Evaluation parameters
  eval_freq: 20000
  eval_episodes: 15
  scripted_eval_freq: 40000
  scripted_eval_episodes: 25
  
  # Checkpointing
  checkpoint_freq: 50000

model:
  transformer:
    token_dim: 10
    embed_dim: 32  # Smaller for 1v1
    num_heads: 2
    num_layers: 2
    max_ships: 2
    num_actions: 6
    dropout: 0.1
    use_layer_norm: true
  
  ppo:
    learning_rate: 5e-4  # Slightly higher for faster learning
    n_steps: 2048
    batch_size: 64
    n_epochs: 8
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.02  # Higher entropy for exploration
    vf_coef: 0.5
    max_grad_norm: 0.5

wandb:
  enabled: false
  project: "space-combat-rl"
  tags: ["1v1", "transformer", "self-play"]

scripted_agent:
  max_shooting_range: 450.0
  angle_threshold: 6.0
  bullet_speed: 500.0
  target_radius: 10.0
  radius_multiplier: 1.3