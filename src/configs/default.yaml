# Default training configuration
environment:
  world_size: [1200, 800]
  max_ships: 4
  agent_dt: 0.04
  physics_dt: 0.02
  memory_size: 1

training:
  game_mode: "2v2"
  learning_team_id: 0
  team_assignments:
    0: [0, 1]  # Team 0 controls ships 0, 1
    1: [2, 3]  # Team 1 controls ships 2, 3
  
  # Opponent configuration
  opponent_type: "mixed"  # "self_play", "scripted", "mixed"
  scripted_mix_ratio: 0.2  # 20% scripted, 80% self-play
  
  # Self-play parameters
  self_play_memory_size: 50
  opponent_update_freq: 10000  # Steps between opponent updates
  self_play_update_freq: 20000  # Steps between adding to memory
  min_steps_before_selfplay: 50000  # Don't use self-play until this many steps
  
  # Training parameters
  total_timesteps: 2000000
  
  # Evaluation parameters
  eval_freq: 25000
  eval_episodes: 10
  scripted_eval_freq: 50000
  scripted_eval_episodes: 20
  
  # Checkpointing
  checkpoint_freq: 100000

model:
  transformer:
    token_dim: 10
    embed_dim: 64
    num_heads: 4
    num_layers: 3
    max_ships: 4
    num_actions: 6
    dropout: 0.1
    use_layer_norm: true
  
  ppo:
    learning_rate: 3e-4
    n_steps: 4096
    batch_size: 128
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5

# Weights & Biases logging
wandb:
  enabled: false
  project: "space-combat-rl"
  tags: ["2v2", "transformer", "self-play"]

# Scripted agent configuration
scripted_agent:
  max_shooting_range: 500.0
  angle_threshold: 5.0
  bullet_speed: 500.0
  target_radius: 10.0
  radius_multiplier: 1.5